{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2938918b-ec01-4ef9-a0e2-e018038d2965",
   "metadata": {},
   "source": [
    "# Project 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ce3b18-c0f4-40a5-991d-f08c5f48f851",
   "metadata": {},
   "source": [
    "#### Jason Kim \n",
    "#### Braulio Lopez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729fbe8-e7e4-4608-9f91-654aca7fa9ad",
   "metadata": {},
   "source": [
    "### Part 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66736b9-cd39-4a22-b85a-25e5d1cba3d2",
   "metadata": {},
   "source": [
    "#### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4e1004-3a64-45ce-811e-56df55181d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in /root/.local/lib/python3.11/site-packages (4.9.4)\n",
      "Requirement already satisfied: absl-py in /root/.local/lib/python3.11/site-packages (from tensorflow_datasets) (1.4.0)\n",
      "Requirement already satisfied: click in /root/.local/lib/python3.11/site-packages (from tensorflow_datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /root/.local/lib/python3.11/site-packages (from tensorflow_datasets) (0.1.8)\n",
      "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /root/.local/lib/python3.11/site-packages (from tensorflow_datasets) (1.8.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (1.26.3)\n",
      "Requirement already satisfied: promise in /root/.local/lib/python3.11/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /root/.local/lib/python3.11/site-packages (from tensorflow_datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (5.9.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /root/.local/lib/python3.11/site-packages (from tensorflow_datasets) (1.14.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.4.0)\n",
      "Requirement already satisfied: toml in /root/.local/lib/python3.11/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /root/.local/lib/python3.11/site-packages (from tensorflow_datasets) (4.66.2)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Requirement already satisfied: array-record>=0.5.0 in /root/.local/lib/python3.11/site-packages (from tensorflow_datasets) (0.5.1)\n",
      "Requirement already satisfied: fsspec in /root/.local/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (2024.3.1)\n",
      "Requirement already satisfied: importlib_resources in /root/.local/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (6.4.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.9.0)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2023.11.17)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /root/.local/lib/python3.11/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.63.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_datasets --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b58f0be6-8d62-42a4-8632-d9ee2638f4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4362/952184717.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-04-10 02:31:58.392249: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-10 02:31:58.440383: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-10 02:31:58.440438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-10 02:31:58.443784: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-10 02:31:58.457675: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-10 02:31:58.458705: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-10 02:31:59.883749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pathlib import Path\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f84642-cfd8-4324-854b-f33f05a5dff9",
   "metadata": {},
   "source": [
    "#### Loading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b56b58-724b-4e7f-96be-df0d02e432ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(\"data_all_modified-cnn-split/train\")\n",
    "    shutil.rmtree(\"data_all_modified-cnn-split/test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd19865-f518-4998-a7fc-a6160da76b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf501608-7bc5-4f02-a270-9d959caab98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data_all_modified-cnn-split/train/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data_all_modified-cnn-split/train/no_damage\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Path(\"data_all_modified-cnn-split/test/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data_all_modified-cnn-split/test/no_damage\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7891e8f8-3642-4860-a3a2-2940f59be0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_damage_file_paths = os.listdir('data_all_modified/damage')\n",
    "all_no_damage_file_paths = os.listdir('data_all_modified/no_damage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f20d6d87-7323-42a0-9865-3cc4093e4f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train damage image count:  11336\n",
      "test damage image count:  2834\n",
      "len of overlap:  0\n",
      "train no damage image count:  5721\n",
      "test no damage image count:  1431\n",
      "len of overlap:  0\n"
     ]
    }
   ],
   "source": [
    "train_damage_paths = random.sample(all_damage_file_paths, int(len(all_damage_file_paths)*0.8))\n",
    "print(\"train damage image count: \", len(train_damage_paths))\n",
    "test_damage_paths = [ p for p in all_damage_file_paths if p not in train_damage_paths]\n",
    "print(\"test damage image count: \", len(test_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_damage_paths if p in test_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))\n",
    "\n",
    "train_no_damage_paths = random.sample(all_no_damage_file_paths, int(len(all_no_damage_file_paths)*0.8))\n",
    "print(\"train no damage image count: \", len(train_no_damage_paths))\n",
    "test_no_damage_paths = [ p for p in all_no_damage_file_paths if p not in train_no_damage_paths]\n",
    "print(\"test no damage image count: \", len(test_no_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_no_damage_paths if p in test_no_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9bcf7-6a93-4e5f-86bb-10fb6274cf9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13040994-3ef9-427a-b31a-9a91ef8ba26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in train/damage:  11336\n",
      "Files in train/no_damage:  5721\n",
      "Files in test/damage:  2834\n",
      "Files in test/no_damage:  1431\n"
     ]
    }
   ],
   "source": [
    "# ensure to copy the images to the directories\n",
    "for p in train_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/damage', p), os.path.join('data_all_modified-cnn-split/train/damage', p) )\n",
    "\n",
    "for p in test_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/damage', p), os.path.join('data_all_modified-cnn-split/test/damage', p) )\n",
    "\n",
    "for p in train_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/no_damage', p), os.path.join('data_all_modified-cnn-split/train/no_damage', p) )\n",
    "\n",
    "for p in test_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/no_damage', p), os.path.join('data_all_modified-cnn-split/test/no_damage', p) )\n",
    "\n",
    "# check counts:\n",
    "print(\"Files in train/damage: \", len(os.listdir(\"data_all_modified-cnn-split/train/damage\")))\n",
    "print(\"Files in train/no_damage: \", len(os.listdir(\"data_all_modified-cnn-split/train/no_damage\")))\n",
    "print(\"Files in test/damage: \", len(os.listdir(\"data_all_modified-cnn-split/test/damage\")))\n",
    "print(\"Files in test/no_damage: \", len(os.listdir(\"data_all_modified-cnn-split/test/no_damage\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61b1b3-a909-4d12-98f3-b58798ead759",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a77897-c056-4bde-b3e1-d571baa148d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17057 files belonging to 2 classes.\n",
      "Using 13646 files for training.\n",
      "Using 3411 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = 'data_all_modified-cnn-split/train'\n",
    "batch_size = 32\n",
    "# target image size\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# note that subset=\"training\", \"validation\", \"both\", and dictates which dataset is returned\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "train_data_dir,\n",
    "validation_split=0.2,\n",
    "subset=\"both\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=batch_size\n",
    ")\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "train_rescale_ds = train_ds.map(lambda image,label:(rescale(image),label))\n",
    "val_rescale_ds = val_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c671c9-48ec-4ae7-a231-8c47e2d9167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4265 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_dir = 'data_all_modified-cnn-split/test/'\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "# this is what was used in the paper --\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# note that subset=\"training\", \"validation\", \"both\", and dictates what is returned\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "test_data_dir,\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    ")\n",
    "\n",
    "# approach 1: manually rescale data --\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "test_rescale_ds = test_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1cf9379-dbda-49b8-aeae-9e4a3ef10b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f994a7-1ce5-4bf1-af50-1609c9c324a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7152 images with dimensions 128x128\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Path to the directory containing your images\n",
    "dataset_dir = 'data_all_modified/no_damage'\n",
    "\n",
    "image_dimensions = {}\n",
    "\n",
    "# Loop through each image file in the directory\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith('.jpeg') or filename.endswith('.png'):  # Adjust file extensions as needed\n",
    "        # Open the image using PIL\n",
    "        img = Image.open(os.path.join(dataset_dir, filename))\n",
    "        # Get the dimensions of the image\n",
    "        width, height = img.size\n",
    "        # Add dimensions to the dictionary\n",
    "        if (width, height) in image_dimensions:\n",
    "            image_dimensions[(width, height)] += 1\n",
    "        else:\n",
    "            image_dimensions[(width, height)] = 1\n",
    "\n",
    "# Print summary of image dimensions\n",
    "for dimensions, count in image_dimensions.items():\n",
    "    print(f\"{count} images with dimensions {dimensions[0]}x{dimensions[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde4d3a-9313-477b-9954-01b2f32c6211",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899295bf-ead7-441b-bf30-5e41cf34f144",
   "metadata": {},
   "source": [
    "#### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cacd882-5a7a-4362-a0aa-87debe2b4156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 49152)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               25166336  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25297921 (96.50 MB)\n",
      "Trainable params: 25297921 (96.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model_ann = models.Sequential()\n",
    "\n",
    "# Adjust the input_shape to match the actual image size\n",
    "model_ann.add(layers.Flatten(input_shape=(128, 128, 3)))  # This line is changed\n",
    "\n",
    "model_ann.add(layers.Dense(512, activation='relu'))\n",
    "model_ann.add(layers.Dropout(0.5))  # Optional: Helps prevent overfitting\n",
    "model_ann.add(layers.Dense(256, activation='relu'))\n",
    "model_ann.add(layers.Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "model_ann.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model_ann.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f036567d-11f8-4fd5-9516-18b4da8d8f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427/427 [==============================] - 59s 138ms/step - loss: 0.6421 - accuracy: 0.6632 - val_loss: 0.6361 - val_accuracy: 0.6681\n"
     ]
    }
   ],
   "source": [
    "history_ann = model_ann.fit(\n",
    "    train_rescale_ds,\n",
    "    epochs=1,\n",
    "    validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "365d9347-6eaf-4709-8b93-517adb9c4525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6383740901947021\n",
      "Test Accuracy: 0.6644783020019531\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_ann.evaluate(test_rescale_ds, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8dc254c-a211-4ef3-99a8-19b23db4c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/ANN_Model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c10fa7-30e6-4cf2-95ff-5ea387fdd3c8",
   "metadata": {},
   "source": [
    "#### LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdcc722f-6d9f-413d-bd36-67eb198a37bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 126, 126, 6)       168       \n",
      "                                                                 \n",
      " average_pooling2d_6 (Avera  (None, 63, 63, 6)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 61, 61, 16)        880       \n",
      "                                                                 \n",
      " average_pooling2d_7 (Avera  (None, 30, 30, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 14400)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 120)               1728120   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 3)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1739587 (6.64 MB)\n",
      "Trainable params: 1739587 (6.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "\n",
    "model_lenet5 = models.Sequential()\n",
    "\n",
    "# Layer 1: Convolutional layer with 6 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(128,128,3)))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2: Convolutional layer with 16 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps to feed into fully connected layers\n",
    "model_lenet5.add(layers.Flatten())\n",
    "\n",
    "# Layer 3: Fully connected layer with 120 neurons\n",
    "model_lenet5.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "# Layer 4: Fully connected layer with 84 neurons\n",
    "model_lenet5.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "# Output layer: Fully connected layer with num_classes neurons (e.g., 3 )\n",
    "model_lenet5.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model_lenet5.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model_lenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "484aa47b-f816-4865-a69a-6023ccd47530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427/427 [==============================] - 23s 53ms/step - loss: 0.6125 - accuracy: 0.6880 - val_loss: 0.5574 - val_accuracy: 0.7640\n"
     ]
    }
   ],
   "source": [
    "#fit the model from image generator\n",
    "history = model_lenet5.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=1,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa118d50-827a-4d65-a150-62bad73e2e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.56317538022995\n",
      "Test Accuracy: 0.7650644779205322\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_lenet5.evaluate(test_rescale_ds, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "234a245e-e177-4c16-816a-1260b125bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/Lenet5_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc92eaf1-712b-4310-858b-8e3cfacd8036",
   "metadata": {},
   "source": [
    "#### Alternate-Lenet-5 CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9644fbe-637c-49be-8d16-5c439801594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17057 images belonging to 2 classes.\n",
      "Found 4265 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4362/1400200379.py:60: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 26s 244ms/step - loss: 0.7610 - acc: 0.6528 - val_loss: 0.7081 - val_acc: 0.6812\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "from keras.regularizers import l2\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3), activation = 'relu', input_shape = (128,128,3)))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3), activation = 'relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation = 'relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation = 'relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation = 'relu', kernel_regularizer = l2(1e-4)))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "#compile the model with RMSprob with learning rate\n",
    "from keras import optimizers\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr=1e-4), metrics = ['acc'])\n",
    "\n",
    "#process the jpeg image\n",
    "#create an image generator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#train using data augmentation and dropout\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale = 1./255,\n",
    "                    rotation_range = 40,\n",
    "                    width_shift_range = 0.2,\n",
    "                    height_shift_range = 0.2,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range = 0.2,\n",
    "                    horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255) #validation data should not be augmented\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    'data_all_modified-cnn-split/train', \n",
    "                    target_size = (128,128),\n",
    "                    batch_size = 32,\n",
    "                    class_mode = 'binary')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                    'data_all_modified-cnn-split/test', \n",
    "                    target_size = (128,128),\n",
    "                    batch_size = 32,\n",
    "                    class_mode = 'binary')\n",
    "\n",
    "#fit the model from image generator\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=100,\n",
    "            epochs=1,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d75e3ba-943b-47a7-beeb-a10efa21276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7222567200660706\n",
      "Test Accuracy: 0.6644783020019531\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_rescale_ds, verbose=0)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d292ee7-cc7e-4c91-864a-0b0fe67972db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/Alternate_Lenet5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85e379-450b-42ff-b233-da803adbb594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
